{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Metadata 1: Designing a Metadata Application Profile\n",
    "\n",
    "This notebook provides information about\n",
    "how to design your metadata application profile (MAP),\n",
    "which is the topic of Assignment 3. This notebook illustrates one element \n",
    "of the \"transform\" process in the larger ETL process.\n",
    "Keep in mind that this kind of work to transform or restructure the metadata\n",
    "is a basic step that you might encounter in different forms in many workflows\n",
    "that involve moving resources from one place to another. This step may often be\n",
    "called by other names, including data wrangling, data cleaning, munging the data,\n",
    "data normalization, or other steps. Whatever you call it, this is a fundamental\n",
    "process in many digital curation activities. One of the \"value adds\" that you\n",
    "can bring as a digital curator (whatever your title) is in providing guidance,\n",
    "expertise, and structure for planning and documenting data transformations.\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "After completing the assignment associated with this notebook, you should: \n",
    "\n",
    "- Be able to explain the concept of metadata extraction and transformation.\n",
    "- Design and plan a structure for documenting metadata practices in a collection or repository, also known as a Metadata Application Profile (MAP). \n",
    "- Understand the role of the MAP in planning and creating ingest-ready (loadable) collection metadata that conforms to Dublin Core and other digital collection metadata standards, which can be used to load content into a collection platform. \n",
    "\n",
    "## Transform the Metadata: Drafting Your MAP\n",
    "\n",
    "* **Transform the metadata.** As illustrated here, there are three substeps: develop the conceptual model for your transformation (expressed in a Metadata Application Profile and an implementation of the MAP in a crosswalk), test the implementation on a small subset, then run your transformation on the entire set.\n",
    "  1. Draft a metadata crosswalk - this is an exploratory activity and you will need to take some time examining one or two sample responses from the previous step to identify the attributes that you want to extract (the goal is to identify the information that you want to import to your Omeka site collection, essentially we are going to recreate the collection), to see how to extract these from the JSON, and to write a test transformation in the next step. This is largely conceptual and, although it is sketched out in this notebook will not use python like the other steps here. That said, the next step does require this step. \n",
    "\n",
    "This notebok illustrates the \"Draft a Metadata Crosswalk\" in the **Transform** step of the above process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refer to the previous Jupyter notebooks to extract the data\n",
    "# and save it locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft and Design a metadata crosswalk Plan\n",
    "\n",
    "The following does not outline the entire design, but it should give you an idea\n",
    "of how to proceed. The assignment requires you to identify at least 10 fields\n",
    "that you want to import into your new site.\n",
    "Most of these will be DublinCore terms, but you must also choose at least one field\n",
    "from another scheme. I would suggest MODS (more of a bibliographic schema and allows for more granularity than DublinCore), since you can also import it into Omeka S (as you have already done in Asst 2b).\n",
    "\n",
    "## Identify and Choose the Fields to Crosswalk\n",
    "\n",
    "In the drafting process, you need to look closely at the metadata that you downloaded\n",
    "in JSON files for each item in the extract process.\n",
    "\n",
    "To do this, use your python skills to investigate one example.\n",
    "It's possible there will be differences between the examples, but even so,\n",
    "this is a good way to start. \n",
    "As a reminder, you will find most of the information you're looking\n",
    "for in the `item` element of the item JSON files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"_version_\": 1731714874606616576,\n",
      "  \"access_restricted\": false,\n",
      "  \"aka\": [\n",
      "    \"https://www.loc.\n"
     ]
    }
   ],
   "source": [
    "# read in a sample file\n",
    "with open(join('..','collection-site-materials','item-metadata','item_metadata-cph.3b41963.json'), encoding='utf-8') as file:\n",
    "    metadata = json.load(file)\n",
    "\n",
    "# check if it's there\n",
    "print(json.dumps(metadata, indent=2)[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call_number :\t SSF - Libraries--Georgia--Cordele <item> [P&P]\n",
      "control_number :\t 91787443\n",
      "created :\t 2016-04-21T09:17:00Z\n",
      "created_published :\t [ca. 1916]\n",
      "created_published_date :\t [ca. 1916]\n",
      "date :\t [ca. 1916]\n",
      "digital_id :\t ['cph 3b41963 //hdl.loc.gov/loc.pnp/cph.3b41963']\n",
      "display_offsite :\t True\n",
      "format :\t ['still image']\n",
      "formats :\t [{'link': 'https://www.loc.gov/pictures/related/?fi=format&q=Photographic%20prints--1910-1920.&co=cph', 'title': 'Photographic prints--1910-1920.'}]\n",
      "genre :\t ['Photographic prints--1910-1920']\n",
      "id :\t 91787443\n",
      "link :\t https://www.loc.gov/pictures/item/91787443/\n",
      "location :\t ['Georgia--Cordele']\n",
      "marc :\t https://www.loc.gov/pictures/item/91787443/marc/\n",
      "medium :\t ['1 photographic print.']\n",
      "medium_brief :\t 1 photographic print.\n",
      "mediums :\t ['1 photographic print.']\n",
      "modified :\t 2016-04-21T09:17:00Z\n",
      "notes :\t ['At bottom right of photo: \"Cordele Book Co.\"', 'Wittemann Collection.']\n",
      "number_former_id :\t ['https://www.loc.gov/item/91787443', 'https://www.loc.gov/item/11583075']\n",
      "other_control_numbers :\t ['11583075']\n",
      "place :\t [{'latitude': '', 'link': 'https://www.loc.gov/pictures/related/?fi=place&q=Georgia--Cordele&co=cph', 'longitude': '', 'title': 'Georgia--Cordele'}]\n",
      "reproduction_number :\t LC-USZ62-95830 (b&w film copy neg.)\n",
      "resource_links :\t ['//hdl.loc.gov/loc.pnp/cph.3b41963']\n",
      "rights_advisory :\t No known restrictions on publication.\n",
      "rights_information :\t No known restrictions on publication.\n",
      "service_low :\t https://tile.loc.gov/storage-services/service/pnp/cph/3b40000/3b41000/3b41900/3b41963_150px.jpg\n",
      "service_medium :\t https://tile.loc.gov/storage-services/service/pnp/cph/3b40000/3b41000/3b41900/3b41963r.jpg\n",
      "sort_date :\t 1916\n",
      "source_created :\t 1991-08-22T00:00:00Z\n",
      "source_modified :\t 2012-06-14T21:04:56Z\n",
      "subject_headings :\t ['Libraries--Georgia--Cordele--1910-1920.', 'Georgia--Cordele']\n",
      "subjects :\t ['Libraries--Georgia--Cordele--1910-1920']\n",
      "summary :\t Photo shows a group of children posed on and in front of steps, roof and dome draped with stars and stripes banners. A Carnegie grant for $10,000 in 1903 funded this building, with an  additional $7,556 in 1916 for remodeling. Still used as a public library.\n",
      "thumb_gallery :\t https://tile.loc.gov/storage-services/service/pnp/cph/3b40000/3b41000/3b41900/3b41963_150px.jpg\n",
      "title :\t Carnegie Library, Cordele, Georgia\n"
     ]
    }
   ],
   "source": [
    "# now take a look at the \"item\" key\n",
    "\n",
    "for attribute in metadata['item'].items():\n",
    "    print(attribute[0], ':\\t', attribute[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reusability, you may want to write this to a file\n",
    "\n",
    "metadata_fields_file = join('..','collection-site-materials','metadata_fields.txt')\n",
    "\n",
    "with open(metadata_fields_file, 'w') as f:\n",
    "    f.write('attribute\\tvalue\\n')\n",
    "    for attribute in metadata['item'].items():\n",
    "        f.write(str(attribute[0]) + '\\t' + str(attribute[1]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above will create a tab-delimited file (aka `.tsv`, like a CSV).\n",
    "You can view it in VSCode as a plain text file, or\n",
    "you can open it in a spreadsheet application like Excel or Sheets.\n",
    "\n",
    "Use that export to start your MAP list. Exploring the data a bit will\n",
    "help you understand the data and develop a transformation plan. For example,\n",
    "the cells below demonstrate how I looked into the date fields and decided what\n",
    "information was best to keep and how to map it.\n",
    "From looking at the previous list exported to the TXT file, I knew that fields with `date` and `created` in their field names were likely to have related information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created\n",
      "created_published\n",
      "created_published_date\n",
      "source_created\n"
     ]
    }
   ],
   "source": [
    "for attribute in metadata.keys():\n",
    "    if 'created' in attribute:\n",
    "        print(attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created_published_date\n",
      "date\n",
      "dates\n",
      "sort_date\n"
     ]
    }
   ],
   "source": [
    "for attribute in metadata.keys():\n",
    "    if 'date' in attribute:\n",
    "        print(attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-04-21T09:17:00Z\n",
      "1916-01-01\n",
      "[ca. 1916]\n",
      "1991-08-22T00:00:00Z\n",
      "[{'1916': 'https://www.loc.gov/search/?dates=1916/1916&fo=json'}]\n"
     ]
    }
   ],
   "source": [
    "created = metadata['created']\n",
    "date = metadata['date']\n",
    "created_published_date = metadata['created_published_date']\n",
    "source_created = metadata['source_created']\n",
    "dates = metadata['dates']\n",
    "\n",
    "print(created)\n",
    "print(date)\n",
    "print(created_published_date)\n",
    "print(source_created)\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear that the 1991 and 2006 dates refer to some collection management action.\n",
    "Look into that another time. The 1916 dates are of most interest.\n",
    "So in this case, the `created_published_date` is most useful.\n",
    "It also maps cleanly to DublinCore's [created](http://purl.org/dc/terms/created) term.\n",
    "It's possible that not all of the items has this field, so I would also focus on the `date` field.\n",
    "\n",
    "Thus, you can start building up your data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': '1916-01-01', 'created': '[ca. 1916]'}\n"
     ]
    }
   ],
   "source": [
    "item_data = {\n",
    "    'date': metadata['date'],\n",
    "    'created': metadata['created_published_date']\n",
    "}\n",
    "\n",
    "print(item_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documenting your decisions\n",
    "\n",
    "For each field that you select to crosswalk into your new collection,\n",
    "you will need to create a MAP entry for each metadata element you choose. \n",
    "\n",
    "For each element, you will make two MAP entries: \n",
    "\n",
    "1. List the term in the MAP table (see example below, or look at the samples linked in the assignment).\n",
    "2. Create a row in the DCTAP profile.\n",
    "\n",
    "For the most part, these are the same information. The first is intended for human readers,\n",
    "while the second is intended for \"machine\" readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking as an example the date fields noted above, a sample MAP entry of the first type might look something like this:\n",
    "\n",
    "| Element Name | date |\n",
    "| --- | ------ |\n",
    "| Label in My New Collection | Date of Creation |\n",
    "| Mapping for My New Collection | dcterms:date |\n",
    "| Description | This is a date extracted from the LOC's original metadata, which indicates when the original resource was scanned or digitized |\n",
    "| Required? | No. Optional, but unless no date was provided in original item, this is strongly encouraged |\n",
    "| Repeatable? | No |\n",
    "| Entry Rules | Use ISO-8601 Date formatting * format should be YYYY, YYYY-MM, or YYYY-MM-DD |\n",
    "| Data Type | literal (a plain string value with ISO-8601 formatting) |\n",
    "| Example Entry | 1916 |\n",
    "| Source (LOC) Attribute Name | date |\n",
    "| DC Mapping | dcterms:date |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DCTAP row for this might look as follows:\n",
    "\n",
    "```csv\n",
    "shapeID,shapeLabel,propertyID,propertyLabel,mandatory,repeatable,valueNodeType,valueDataType,valueConstraint,valueConstraintType,valueShape,note\n",
    "       ,          ,dcterms:title,Title,TRUE,FALSE,literal,xsd:string,,,,\n",
    "       ,           ,dcterms:date,Date,FALSE,FALSE,literal,xsd:date,,,,\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing your crosswalking implementation script\n",
    "\n",
    "This is actually in preparation for Assignment 4 (your transformation script),\n",
    "but in practice and concept these two steps are linked.\n",
    "\n",
    "Simultaneously, start to make notes about how you will map the original fields\n",
    "to the destinations for your new collection sites.\n",
    "A good way to do this is to start a spreadsheet file, which you could base on the previously exported TSV file.\n",
    "Or, you can [use a template like this one designed in Google Sheets for the course](https://docs.google.com/spreadsheets/d/1m2nq-PInOIN1GTRKRVGtKtc5qI0DTojw6waMe5hVzMc/edit?usp=sharing).\n",
    "\n",
    "In looking through these files, you will not find the exact matches for each data element in the JSON,\n",
    "but you should find clear parallels between the source data, DublinCore, and/or MODS.\n",
    "Your goal should be to crosswalk as much as possible from the items\n",
    "into your new collection presentation sites.\n",
    "\n",
    "Here's a draft table to start the process:\n",
    "\n",
    "\n",
    "| source field name | source field path/dict name | target | target namespace | notes |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| title | item['title'] | dc:title | DCTerms | Title provided by the orginal metadata, could also be mapped to MODS:titleInfo:title or other fields in other namespaces | \n",
    "| date | item['date'] | dc:date | DCTerms | This is a 4-digit year, corresponds to date of creation in most cases |\n",
    "| LC control number | item['item']['control_number'] | dc:identifier @type=lccn | DC Element with attribute | Corresponds to the Library of Congress Control Number |\n",
    "| creator | item['creator'] | dc:creator | DCTerms | Should be a name. May be repeated. If possible, are various roles needed? Such as 'photographer', 'author', etc. |\n",
    "| description | item['description'] \\/ item['summary'] | mods:physicaldescription | MODS | In the source data, this seems most like physical description, although it might correspond to dc:format or dc:type. Content in the record may come from a controlled vocabulary, such as LC Genre & Form Thesaurus. |\n",
    "| format, physical | item['type'] | mods:physicalDescription:form | MODS | Description of the original physical format of this item \\(photograph, book, poster\\). _Note:_ this may not be present or in the same place for the different types of objects in the collection |\n",
    "| format | item['format'] | dc:format | DCTerms | The basic type of the digital surrogate \\(e.g., 'image' or 'text'\\) |\n",
    "| notes (may be multiple) | item['notes'] (array) | dcterms:abstract | DC Terms | This appears to be closest to a \"summary\" or description of the content of the items. |\n",
    "| subject_heading | | mods:subject | mods | |\n",
    "| source_collection | | | | |\n",
    "| rights | | | | |\n",
    "| place | | | | |\n",
    "| languages | | | | |\n",
    "| mime_type | | | DCTerms | |\n",
    "\n",
    "**Note:** this table does not include information about the digital assets,\n",
    "it's only about the descriptive metadata."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
