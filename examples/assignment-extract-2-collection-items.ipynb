{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract (Harvest) Item Metadata and Files\n",
    "\n",
    "This notebook demonstrates the next step in the generalized workflow\n",
    "to develop your reference digital collections. \n",
    "We will walk through each step in class, but you will need to adapt these demonstrations\n",
    "so that they work for your own collections, so this work will also be self-guided.\n",
    "\n",
    "## ETL Workflow\n",
    "\n",
    "The overarching process here follows a generalized \"Extract - Transform - Load\" workflow.This is an abstract model for pulling data from one system, transporting, cleaning, and outputting to another system.\n",
    "While often in reference to database work and data engineering, the goals here are the same for our digital collections:\n",
    "**extract** the metadata from the Library of Congress, change (**transform**) it into structures that makes sense to our collection systems (CollectionBuilder and Omeka),\n",
    "then ingest (**load**) that data and associated content into the systems.\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "After completing the course assignment, you should: \n",
    "\n",
    "* Have a conceptual and a practical understanding of how collection metadata is made available by a REST API.\n",
    "* Be able to explain the concept of metadata extraction and transformation.\n",
    "* Create a structure for documenting metadata practices in a collection or repository (a Metadata Application Profile) and implement that structure for transformations. \n",
    "* Use programming to work with data supplied by an API in JSON format, to manage and transform useful parts of that data into CSV format.\n",
    "* Create ingest-ready collection metadata that conforms to Dublin Core and other digital collection metadata standards, which can be used to load content into another site (in this case, an Omeka S site). \n",
    "\n",
    "## Introduction: Get Item Metadata and Content\n",
    "\n",
    "This notebook outlines the second steps of the extract process to demonstrate gathering items. In this notebook:\n",
    "\n",
    "**Get item metadata**. Using the list from the previous step (extract collection list), use that as a source to query each item in the collection to get details about it. Save the JSON responses locally so we can extract information from them in the next steps. (In this example, you will create a maximum of 62 item files, but it is likely that some will not be accessible or available. This number may vary when you run this code yourself since the website may have different response rates.)\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# for working with files\n",
    "import os\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A helper function to regenerate the collection list from the previously created CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regenerate_collection_list(collection_csv):\n",
    "    \"\"\"\n",
    "    Reads a CSV file and returns the data as a dictionary.\n",
    "    \n",
    "    Parameters:\n",
    "    collection_csv (str): The path to the CSV file\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where each key is a column header and each value is a list of column values.\n",
    "    \"\"\"\n",
    "\n",
    "    coll_items = list()\n",
    "\n",
    "    with open(collection_csv, 'r', newline='', encoding='utf-8') as f:\n",
    "        data = csv.DictReader(f)\n",
    "\n",
    "        for row in data:\n",
    "            row_dict = dict()\n",
    "            for field in data.fieldnames:\n",
    "                row_dict[field] = row[field]\n",
    "            coll_items.append(row_dict)\n",
    "\n",
    "        return coll_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_csv = os.path.join('..','collection-project','collection_set_list.csv')\n",
    "\n",
    "collection_set_list = regenerate_collection_list(collection_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_set_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get metadata for individual items \n",
    "\n",
    "Now that you have the list of what is in the set, this can serve as your baseline collection information. Next, you want to get more complete information about each item. Details about these items are available on individual item pages, so now we have to look at a different location, as specified in the `'link'` fields of the item list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update baseURL\n",
    "baseURL = 'https://www.loc.gov'\n",
    "parameters = {\n",
    "    'fo' : 'json'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task now is to request metadata for each item. So that the data is reusable, save it locally as a JSON file. In the next blocks, you will create individual files for each item, which will save to a directory named `item-metadata` in the `collection-project` directory. \n",
    "\n",
    "If you don't have that directory, you will first need to create it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to confirm that you have a location for the JSON files\n",
    "item_metadata_directory = os.path.join('..','collection-project','item-metadata')\n",
    "\n",
    "if os.path.isdir(item_metadata_directory):\n",
    "    print(item_metadata_directory,'exists')\n",
    "else:\n",
    "    os.mkdir(item_metadata_directory)\n",
    "    print('created',item_metadata_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with the `collection_set_list`, use the included links to query the API for metadata for each item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_count = 0\n",
    "error_count = 0\n",
    "file_count = 0\n",
    "\n",
    "data_directory = 'collection-project'\n",
    "item_metadata_directory = 'item-metadata'\n",
    "item_metadata_file_prefix = 'item_metadata'\n",
    "json_suffix = '.json'\n",
    "\n",
    "for item in collection_set_list:\n",
    "    if item['link'] == 'link':\n",
    "        continue\n",
    "    # these resource links could redirect to item pages, but currently don't work\n",
    "    if '?' in item['link']:\n",
    "        resource_ID = item['link']\n",
    "        short_ID = item['link'].split('/')[2]\n",
    "        item_metadata = requests.get(baseURL + resource_ID, params={'fo':'json'})\n",
    "        print('requested',item_metadata.url,item_metadata.status_code)\n",
    "        if item_metadata.status_code != 200:\n",
    "            print('requested',item_metadata.url,item_metadata.status_code)\n",
    "            error_count += 1\n",
    "            continue\n",
    "        try:\n",
    "            item_metadata.json()\n",
    "        except: #basically this catches all of the highsmith photos with hhh in the ID\n",
    "            error_count += 1\n",
    "            print('no json found')\n",
    "            continue\n",
    "        fout = os.path.join('..',data_directory, item_metadata_directory, str(item_metadata_file_prefix + '-' + short_ID + json_suffix))\n",
    "        with open(fout, 'w', encoding='utf-8') as json_file:\n",
    "            json_file.write(json.dumps(item_metadata.json()['item']))\n",
    "            file_count += 1\n",
    "            print('wrote', fout)\n",
    "        item_count += 1\n",
    "    else:\n",
    "        resource_ID = item['link']\n",
    "        short_ID = item['link'].split('/')[2]\n",
    "        item_metadata = requests.get(baseURL + resource_ID, params={'fo':'json'})\n",
    "        print('requested',item_metadata.url,item_metadata.status_code)\n",
    "        if item_metadata.status_code != 200:\n",
    "            print('requested',item_metadata.url,item_metadata.status_code)\n",
    "            error_count += 1\n",
    "            continue\n",
    "        try:\n",
    "            item_metadata.json()\n",
    "        except:\n",
    "            error_count += 1\n",
    "            print('no json found')\n",
    "            continue\n",
    "        fout = os.path.join('..',data_directory, item_metadata_directory, str(item_metadata_file_prefix + '-' + short_ID + json_suffix))\n",
    "        with open(fout, 'w', encoding='utf-8') as json_file:\n",
    "            json_file.write(json.dumps(item_metadata.json()['item']))\n",
    "            file_count += 1\n",
    "            print('wrote', fout)\n",
    "        item_count += 1\n",
    "\n",
    "print('--- mini LOG ---')\n",
    "print('items requested:',item_count)\n",
    "print('errors:',error_count)\n",
    "print('files written:',file_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get files for items\n",
    "\n",
    "This section uses the file processing libraries and saves an image file for each item.\n",
    "\n",
    "First, check to confirm that there is a directory in the `collection-project` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = os.path.join('/','Users','jajohnst','Desktop','si676-2024-data')\n",
    "project_dir = 'collection-project'\n",
    "files_dir = 'item-files'\n",
    "metadata_dir = 'item-metadata'\n",
    "\n",
    "files_loc = os.path.join(main_dir,project_dir,files_dir)\n",
    "print('Checking for',files_loc)\n",
    "\n",
    "# check directory\n",
    "if os.path.isdir(files_loc):\n",
    "    print('Files directory exists')\n",
    "else:\n",
    "    os.mkdir(files_loc)\n",
    "    print('Created file directory:',files_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, since you have the local files, it is no longer necessary to\n",
    "harvest the data using requests. You can use the `glob` library to\n",
    "search for files with filters and wildcards similar to the `ls` command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of the item metadata files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_for_metadata_here = os.path.join('..',project_dir,metadata_dir)\n",
    "\n",
    "print(search_for_metadata_here)\n",
    "\n",
    "metadata_file_list = glob.glob(search_for_metadata_here + '/*.json')\n",
    "\n",
    "print(metadata_file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the Image URLs from the stored data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_image_urls = list()\n",
    "count = 0\n",
    "\n",
    "for item in metadata_file_list:\n",
    "    with open(item, 'r', encoding='utf-8') as f:\n",
    "        metadata = json.load(f)\n",
    "        # noted this resource for working out index out of range errors: https://rollbar.com/blog/how-to-fix-python-list-index-out-of-range-error-in-for-loops/\n",
    "        image_url_no = len(metadata['image_url'])\n",
    "        image_url = metadata['image_url'][-1]\n",
    "        item_image_urls.append(image_url)\n",
    "        count += 1\n",
    "\n",
    "print(f'Identified { str(count) } image URLs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_image_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create an updated set list with the image URLs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_set_list_with_images = list()\n",
    "\n",
    "for item in metadata_file_list:\n",
    "    with open(item, 'r', encoding='utf-8') as item_info:\n",
    "        item_metadata = json.load(item_info)\n",
    "\n",
    "        # add the metadata into a dictionary for each item\n",
    "        item_metadata_dict = dict()\n",
    "        item_metadata_dict['item_URI'] = item_metadata['id']\n",
    "        try:\n",
    "            item_metadata_dict['lccn'] = item_metadata['library_of_congress_control_number']\n",
    "        except:\n",
    "            item_metadata_dict['lccn'] = None\n",
    "        item_metadata_dict['title'] = item_metadata['title']\n",
    "        item_metadata_dict['image_URL_large'] = item_metadata['image_url'][-1]\n",
    "        \n",
    "        # add the metadata to the main list\n",
    "        collection_set_list_with_images.append(item_metadata_dict)\n",
    "\n",
    "print(collection_set_list_with_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, make the image requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_count = 0\n",
    "error_count = 0\n",
    "file_count = 0\n",
    "\n",
    "img_file_prefix = 'img_'\n",
    "\n",
    "for item in collection_set_list_with_images:\n",
    "        image_URL = item['image_URL_large']\n",
    "        short_ID = item['item_URI'].split('/')[-2]\n",
    "        print('... requesting',image_URL)\n",
    "        item_count += 1\n",
    "\n",
    "        # if found, save image\n",
    "        r = requests.get(image_URL)\n",
    "        if r.status_code == 200:\n",
    "            img_out = os.path.join('..',project_dir,files_dir,str(img_file_prefix + short_ID + '.jpg'))\n",
    "            with open(img_out, 'wb') as file:\n",
    "                file.write(r.content)\n",
    "                print('Saved',img_out)\n",
    "                file_count += 1\n",
    "\n",
    "\n",
    "print('--- mini LOG ---')\n",
    "print('files requested:',item_count)\n",
    "print('errors:',error_count)\n",
    "print('files written:',file_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
